{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Kütüphaneleri ekleme işlemi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. ImageDataGenerator Nedir?\n",
    "\n",
    "Keras'ın ImageDataGenerator sınıfı, özellikle görüntü veri setleriyle çalışırken, veri ön işleme ve veri artırma (augmentation) işlemleri için kullanılır. Bu sınıf, özellikle büyük veri kümelerinde veriyi anlık olarak (batch halinde) yükler ve aynı zamanda veri çeşitliliğini artırmak için bazı işlemler (döndürme, yakınlaştırma, yatay yansıtma, vb.) uygular.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ImageDataGenerator oluştur\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### 2. Eğitim Verilerinin Yüklenmesi\n",
    "\n",
    "target_size=(150, 150): Bu parametre, tüm görüntülerin 150x150 piksel boyutuna yeniden ölçeklenmesini sağlar. Modelin sabit boyutlarda girdi alması gerektiği için bu adım önemlidir.\n",
    "\n",
    "batch_size=32: Bu parametre, modelin her seferinde kaç görüntüyle eğitileceğini belirtir. Yani, veriler her seferinde 32'lik gruplar (batch) halinde modele verilir. Bu, özellikle belleğin verimli kullanılması için önemlidir.\n",
    "\n",
    "class_mode='categorical': Çoklu sınıf sınıflandırması yapıyorsan bu parametreyi kullanırsın. Görüntüler birden fazla sınıfa (örneğin: buildings, forest, glacier, vb.) ait olabilir, bu nedenle etiketler one-hot encoded bir biçimde verilir. Eğer ikili sınıflandırma (binary classification) olsaydı, class_mode='binary' olurdu.\n",
    "\n",
    "subset='training': validation_split kullanıldığı için, bu parametre eğitim verilerini belirtir. Yani, doğrulama için ayrılmamış olan %80'lik kısmı eğitim için kullanır."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 11230 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "# Eğitim verilerini yükle\n",
    "train_generator= train_datagen.flow_from_directory(\n",
    "    'data\\seg_train\\seg_train',\n",
    "    target_size=(150,150), #Veri setindeki her görseli resize etme işlemi\n",
    "    batch_size=8,# Modele aynı anda kaç görüntü gireceği\n",
    "    class_mode = \"categorical\",# Modelde 1 den fazla sınıf olacaksa onun tanımlanması içi categorical\n",
    "    subset='training'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Doğrulama Verilerinin Yüklenmesi\n",
    "\n",
    "subset='validation': Eğitim verisinin bir kısmı doğrulama için ayrılmıştı. Bu kısım, validation (doğrulama) verilerini yükler. Eğitim sırasında, model her epoch sonunda doğrulama verisi üzerinde test edilir ve sonuçlara göre modelin genel performansı izlenir.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2804 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    'data\\seg_train\\seg_train',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=8,\n",
    "    class_mode='categorical',\n",
    "    subset='validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 images belonging to 6 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    'data/seg_test/seg_test',\n",
    "    target_size=(150, 150),\n",
    "    batch_size=8,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_datagen.channel_axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'buildings': 0,\n",
       " 'forest': 1,\n",
       " 'glacier': 2,\n",
       " 'mountain': 3,\n",
       " 'sea': 4,\n",
       " 'street': 5}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.class_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150, 3)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.image_shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Mimarisi Oluşturma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D,MaxPooling2D,Flatten,Dropout,Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_3 (Conv2D)           (None, 150, 150, 16)      208       \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 75, 75, 16)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 75, 75, 32)        2080      \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPoolin  (None, 37, 37, 32)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 37, 37, 64)        8256      \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPoolin  (None, 18, 18, 64)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 18, 18, 64)        0         \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 20736)             0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 512)               10617344  \n",
      "                                                                 \n",
      " dropout_3 (Dropout)         (None, 512)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 3078      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10630966 (40.55 MB)\n",
      "Trainable params: 10630966 (40.55 MB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(filters=16,kernel_size=2,padding=\"same\",strides=1,activation=\"relu\",input_shape=(150,150,3)))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=32,kernel_size=2,padding=\"same\",strides=1,activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Conv2D(filters=64,kernel_size=2,padding=\"same\",strides=1,activation=\"relu\"))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Dropout(0.3))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512,activation=\"relu\"))\n",
    "\n",
    "model.add(Dropout(0.4))\n",
    "\n",
    "model.add(Dense(6,activation=\"softmax\"))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='rmsprop',\n",
    " metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11230"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_generator.samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1,\n",
    " save_best_only=True)\n",
    "# Modeli eğitme (fit)\n",
    "\n",
    "\n",
    "hist = model.fit(\n",
    "    train_generator,  # Eğitim verisi generator\n",
    "    steps_per_epoch=train_generator.samples // train_generator.batch_size,  # Eğitim için gereken adım sayısı\n",
    "    validation_data=validation_generator,  # Doğrulama verisi generator\n",
    "    validation_steps=validation_generator.samples // validation_generator.batch_size,  # Doğrulama için gereken adım sayısı\n",
    "    epochs=100,  # Kaç epoch eğitim yapılacağı\n",
    "    callbacks=[checkpointer],  # En iyi modeli kaydetme callback'i\n",
    "    verbose=2,  # Eğitim sırasında daha az detaylı çıktı almak için 2 (ya da daha fazla bilgi için 1)\n",
    "    shuffle=True  # Eğitim verilerini karıştırma\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_generator ve validation_generator:\n",
    "\n",
    "-->train_generator ve validation_generator dizinlerden veriyi yükleyen flow_from_directory fonksiyonu ile oluşturuldu. Model, bu generator'lardan veriyi çekerek eğitim yapacak.\n",
    "steps_per_epoch:\n",
    "\n",
    "-->Bu parametre, bir epoch sırasında kaç adımda eğitim verisinin işleneceğini belirtir. Her batch bir adım olduğundan, steps_per_epoch değeri train_generator.samples // train_generator.batch_size olarak ayarlandı. Bu, tüm verinin bir epoch'ta işlenmesini sağlar.\n",
    "    validation_steps:\n",
    "\n",
    "-->Doğrulama verisi için kaç adımda işlemin tamamlanacağını belirtir. Aynı mantıkla, validation_steps, validation_generator.samples // validation_generator.batch_size olarak hesaplanır.\n",
    "    epochs:\n",
    "\n",
    "-->Modelin kaç epoch boyunca eğitileceğini belirler. Bu örnekte 100 epoch seçildi.\n",
    "    callbacks:\n",
    "\n",
    "-->Model eğitilirken, en iyi doğrulama başarımına sahip olan modelin ağırlıklarının (model.weights.best.hdf5) kaydedilmesi için ModelCheckpoint callback kullanılıyor. Bu, overfitting'den kaçınmak ve en iyi modeli almak için yararlıdır.\n",
    "Bu şekilde, dizinlerde organize edilen verilerle modelini eğitebilirsin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "\n",
    "checkpointer = ModelCheckpoint(filepath='model.weights.best.hdf5', verbose=1,\n",
    " save_best_only=True)\n",
    "# Modeli eğitme (fit)\n",
    "\n",
    "\n",
    "hist = model.fit(\n",
    "    train_generator,  # Eğitim verisi generator\n",
    "    validation_data=validation_generator,  # Doğrulama verisi generator\n",
    "    epochs=100,  # Kaç epoch eğitim yapılacağı\n",
    "    callbacks=[checkpointer],  # En iyi modeli kaydetme callback'i\n",
    "    verbose=2,  # Eğitim sırasında daha az detaylı çıktı almak için 2 (ya da daha fazla bilgi için 1)\n",
    "    shuffle=True  # Eğitim verilerini karıştırma\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
